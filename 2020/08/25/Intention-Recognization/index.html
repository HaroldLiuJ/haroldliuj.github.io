<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="IntroductionHello, nice to meet you! This is my summary of my recent learning and it will continue updating for some time since I’m still learning. I will summarize some method of Intention Recognizat">
<meta name="keywords" content="NLP,Paper Reading">
<meta property="og:type" content="article">
<meta property="og:title" content="Intention Recognization">
<meta property="og:url" content="http://yoursite.com/2020/08/25/Intention-Recognization/index.html">
<meta property="og:site_name" content="Xiao Liu&#39;s Blog">
<meta property="og:description" content="IntroductionHello, nice to meet you! This is my summary of my recent learning and it will continue updating for some time since I’m still learning. I will summarize some method of Intention Recognizat">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2020/08/25/Intention-Recognization/ham.png">
<meta property="og:updated_time" content="2020-08-27T09:25:31.808Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Intention Recognization">
<meta name="twitter:description" content="IntroductionHello, nice to meet you! This is my summary of my recent learning and it will continue updating for some time since I’m still learning. I will summarize some method of Intention Recognizat">
<meta name="twitter:image" content="http://yoursite.com/2020/08/25/Intention-Recognization/ham.png">
  <link rel="canonical" href="http://yoursite.com/2020/08/25/Intention-Recognization/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Intention Recognization | Xiao Liu's Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xiao Liu's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-photos">
      
    

    <a href="/photos/" rel="section"><i class="fa fa-fw fa-image"></i>Photos</a>

  </li>
      
    
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/25/Intention-Recognization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Xiao Liu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiao Liu's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            Intention Recognization
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-08-25 17:01:28" itemprop="dateCreated datePublished" datetime="2020-08-25T17:01:28+08:00">2020-08-25</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-27 17:25:31" itemprop="dateModified" datetime="2020-08-27T17:25:31+08:00">2020-08-27</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/English-Articles/" itemprop="url" rel="index">
                    <span itemprop="name">English Articles</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/08/25/Intention-Recognization/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/08/25/Intention-Recognization/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hello, nice to meet you! This is my summary of my recent learning and it will continue updating for some time since I’m still learning. I will summarize some method of Intention Recognization that I learned from paper recently. I will just show the main idea about a specific without too many details. I will list the paper that corresponding to the topic that I’m showing below. If you are interested in some topics, you can find the original paper and get more details. Always, if you want to talk with me, please contact me at haroldliuj@gmail.com. Let’s get Started! Have a nice trip!</p><a id="more"></a>
<h1 id="1-Word-Embedding-Based-Correlation-Model-for-Question-Answer-Matching"><a href="#1-Word-Embedding-Based-Correlation-Model-for-Question-Answer-Matching" class="headerlink" title="1. Word Embedding Based Correlation Model for Question/Answer Matching"></a>1. Word Embedding Based Correlation Model for Question/Answer Matching</h1><p>This paper is proposed by Yikang Shen, Wenge Rong, Nan Jiang, Baolin Peng, Jie Tang and Zhang Xiong. They introduced one method of computing the relationship between Q&amp;A(Question &amp; Answer) Pairs. They propesed a word level correlation function so that they can compute the correlation between a Q&amp;A pair. The word level correlation function is:</p>
<script type="math/tex; mode=display">
C\left(q_{i}, a_{j}\right)=\cos <v_{q_{i}}, \mathbf{M} v_{a_{j}}>=\frac{v_{q_{i}}^{\mathrm{T}}}{\left\|v_{q_{i}}\right\|} \frac{\mathbf{M} v_{a_{j}}}{\| \mathbf{M} v_{a_{j}} \mid}</script><p>where $v_{q_i}$ is the i-th word vector of the question $q$ and $v_{a_j}$ is the j-th word vector of the answer $a$ and $\mathbf{M}$ is a trainable weight matrix and it is called translation matrix, because it maps word in the answer into a possible correlated word in the question.</p>
<p>This is technically an “improved cosine similarity” which is trainable by the data.</p>
<p>Having the word level correlation function, we can then computer the sentence level corelation:</p>
<script type="math/tex; mode=display">
C(q, a)=\frac{1}{|a|} \sum_{j} \max _{i} C\left(q_{i}, a_{j}\right)</script><p>where $|a|$ is the number of answers.</p>
<p>With this correlation function, we can either map Question and Answer directly or use it as the input of the neural networks. The authors gave an example of CNN in the paper. </p>
<h1 id="2-Hybrid-Attentive-Answer-Selection-in-CQA-with-Deep-Users-Modeling"><a href="#2-Hybrid-Attentive-Answer-Selection-in-CQA-with-Deep-Users-Modeling" class="headerlink" title="2. Hybrid Attentive Answer Selection in CQA with Deep Users Modeling"></a>2. Hybrid Attentive Answer Selection in CQA with Deep Users Modeling</h1><p>This method is proposed by Jiahui Wen, Jingwei Ma, Yiliu Feng and Mingyang Zhong. They gave out a method that can take both the local and the mutual importance of the word in QA pairs into consideration called <strong>Hybrid</strong> <strong>Attention</strong> <strong>Mechanism</strong>. They also gave a method the model users expertises. Since user expertises is not my main focus, I will just skip this part and pay my attention more on Hybrid Attention Mechanism.</p>
<p>Their model architecture is shown below:</p>
<p><img src="/2020/08/25/Intention-Recognization/ham.png" alt></p>
<p>The left part is about user modeling which I won’t talk about here. Let’s just see the right part. The bottom half part of the model is quite normal, they map the question and answer into word vector space and passed two encoders for questions and answers separately. The real show is is that green bar called “Interaction Attention”. This is their main contribution. I will explain them with more details later. </p>
<p>Firstly, the authors calculated attention weights for the words in question and answer sentences separately. Here, they just showed the whole process for the question, the answer has the same process as the question. The expression for the individual attention for question is:</p>
<script type="math/tex; mode=display">
\alpha^q = \operatorname{softmax}(w_1^T\mathbf{H}^q)</script><p>where $\mathbf{H}^q$ is the output of LSTM($\mathbf{H}^{q}=\left\{\mathbf{h}_{t}^{q}\right\}_{t=1}^{L^{q}}=L S T M\left(\left\{\mathbf{x}_{t}^{q}\right\}_{t=1}^{L^{q}}\right)$) and $w_1$ is a trainable transformation <strong>vector</strong>. $\alpha_i^q$ indicating the importance of i-th word in the question sentence. </p>
<p>Then they calculated the attention over the words in one sentence for each word in the conterpart sentence. Let $\mathbf{h}_i^q$ be the hidden vector for the i-th word in a question sentence and $\mathbf{h}_j^a$ be the hidden vector for the j-th word in the corresponding answer sentence, the the question word’s attention over the answer words is obtained as:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{m}_{i j} &=\tanh \left(\mathbf{W}^q\mathbf{h}_{i}^{q}+\mathbf{W}^{a} \mathbf{h}_{j}^{a}+\mathbf{W}^{q a}\left(\mathbf{h}_{i}^{q} \odot \mathbf{h}_{j}^{a}\right)\right) \\
\gamma_{i}^{q} &=\operatorname{softmax}\left(\mathbf{w}_{2}^{T} \mathbf{m}_{i,:}\right) \\
\beta_{i}^{q} &=\mathbf{H}\left(\gamma_{i}^{q}\right)
\end{aligned}</script><p>where $\mathbf{W}^q, \mathbf{W}^a, \mathbf{W}^{qa}$ are trainable transformation matrices, $\mathbf{w}_2$ is a trainable <strong>vector</strong> and $\odot$ is the element-wise multiplication of two vectors. In this “inter-sentece attention” part, authors first calculated the interaction between each questions words and each answer words with non-linear transformation. $\gamma_i^q$ is a vector containing attentions over the words in the answer for i-th word in the question. $\beta_i^q$ is the information entropy of the attention vector, and it implies the mutual importance of i-word for q-a matching task.</p>
<p>Finally, the representation of a question can be summarized as:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\eta_{i} &=\frac{\exp \left(\alpha_{i}^{q} / \beta_{i}^{q}\right)}{\sum_{j} \exp \left(\alpha_{j}^{q} / \beta_{j}^{q}\right)} \\
\tilde{\mathbf{h}}^{q} &=\sum_{i=1}^{L^{q}} \eta_{i} \mathbf{h}_{i}^{q}
\end{aligned}</script><p>This is technically the combination of $\alpha$ aka the individual attention and $\beta$ aka the inter-sentence attention. The explaination from the authors of the expression is: if a word is locally important but does not align well with the word in the counterpart sentence, it needs to be endowed with less importance as it is useless for semantic matching. On the other hand, if a word is highly related to the counterpart sentence but is not a keyword, it should be neglected as it can mislead sentence matching.</p>
<p>We can computer $\tilde{h}^a$ in a similar way.</p>
<p>With $\tilde{h}^a$ and $\tilde{h}^q$ we can give them to a hidden layer whose activation is tanh:</p>
<script type="math/tex; mode=display">
\mathbf{h}=\tanh \left(\tilde{\mathbf{W}}^{q} \tilde{\mathbf{h}}^{q}+\tilde{\mathbf{W}}^{a} \tilde{\mathbf{h}}^{a}\right)</script><p>Finially we can get the output from a dense layer with a softmax activation:</p>
<script type="math/tex; mode=display">
output = \operatorname{softmax}(\mathbf{w}\mathbf{h} + \mathbf{b})</script><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://arxiv.org/pdf/1511.04646.pdf" target="_blank" rel="noopener">Shen Y, Rong W, Jiang N, et al. Word embedding based correlation model for question/answer matching[J]. arXiv preprint arXiv:1511.04646, 2015.</a></li>
<li>Wen J, Ma J, Feng Y, et al. Hybrid attentive answer selection in cqa with deep users modelling[C]//Thirty-Second AAAI Conference on Artificial Intelligence. 2018.</li>
</ul>

    </div>

    
    
    
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/NLP/" rel="tag"># NLP</a>
            
              <a href="/tags/Paper-Reading/" rel="tag"># Paper Reading</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/08/17/GSDMM/" rel="next" title="Gibbs Sampling for Dirichlet Multinomial Mixture Reading Notes">
                  <i class="fa fa-chevron-left"></i> Gibbs Sampling for Dirichlet Multinomial Mixture Reading Notes
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2020/09/09/bert/" rel="prev" title="Intention Recognization - BERT & BERT Variants">
                  Intention Recognization - BERT & BERT Variants <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Word-Embedding-Based-Correlation-Model-for-Question-Answer-Matching"><span class="nav-number">2.</span> <span class="nav-text">1. Word Embedding Based Correlation Model for Question/Answer Matching</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Hybrid-Attentive-Answer-Selection-in-CQA-with-Deep-Users-Modeling"><span class="nav-number">3.</span> <span class="nav-text">2. Hybrid Attentive Answer Selection in CQA with Deep Users Modeling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">3.0.1.</span> <span class="nav-text">Reference</span></a></li></ol></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.jpg"
      alt="Xiao Liu">
  <p class="site-author-name" itemprop="name">Xiao Liu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/haroldliuj" title="GitHub &rarr; https://github.com/haroldliuj" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:haroldliuj@gmail.com" title="E-Mail &rarr; mailto:haroldliuj@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://www.instagram.com/haroldlogspace/" title="Instagram &rarr; https://www.instagram.com/haroldlogspace/" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao Liu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'FoLSl7NpGs5fSxnb59tfNULA-gzGzoHsz',
    appKey: 'Yl577c0mRRb9AIFa03rdU8c1',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
